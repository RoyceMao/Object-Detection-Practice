{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RPN的分类与回归损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Royce\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分类loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax_cross_entropy函数在tf.nn包里，可直接调用，故这里不需要自己重新定义\n",
    "def rpn_cls_loss(predict_cls_ids, true_cls_ids, indices):\n",
    "    \"\"\"\n",
    "    rpn分类损失\n",
    "    :param predict_cls_ids: 预测的anchors类别，(batch_num,anchors_num,2) fg or bg      （所有anchors前向传播做分类预测）\n",
    "    :param true_cls_ids:实际的anchors类别，(batch_num,rpn_train_anchors,(class_id,tag))（部分anchors真实值用来计算loss，只区分前景1、背景0）\n",
    "             tag 1：正样本，-1：负样本，0 padding\n",
    "    :param indices: 正负样本索引，(batch_num,rpn_train_anchors,(idx,tag))，            （部分anchors真实值在所有anchors里面的索引）\n",
    "             idx:指定anchor索引位置，tag 1：正样本，-1：负样本，0 padding\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 真实值去除padding\n",
    "    train_indices = tf.where(tf.not_equal(indices[...,-1], 0)) # 2维tensor\n",
    "    train_anchor_indices = tf.gather_nd(indices[...,0], train_indices) # 3维tensor确定1个维度，然后gather_nd选定索引2维tensor，最终返回（batch_num*rpn_train_anchors）的1维tensor\n",
    "    true_cls_ids = tf.gather_nd(true_cls_ids[...,0], train_indices) # 同样也是返回长度为（batch_num*rpn_train_anchors）的1维cls\n",
    "    \n",
    "    # 真实值one-hot编码\n",
    "    true_cls_ids = tf.where(true_cls_ids > 0,\n",
    "                            tf.ones_like(true_cls_ids, dtype=tf.uint8),\n",
    "                            tf.zeros_like(true_cls_ids, dtype=tf.uint8))\n",
    "    true_cls_ids_one_hot = tf.one_hot(true_cls_ids, depth=2) # depth=2表示labels只有2种，1种前景，1种背景\n",
    "    # anchors的2维indices索引,与predict的anchors中用于训练的anchors提取\n",
    "    batch_indices = train_indices[:, 0]\n",
    "    train_anchor_indices_2d = tf.stack([batch_indices, tf.cast(train_anchor_indices, dtype=tf.int64)], axis=1)\n",
    "    predict_cls_ids = tf.gather_nd(predict_cls_ids, train_anchor_indices_2d)\n",
    "    # 交叉熵损失\n",
    "    losses = tf.nn.softmax_cross_entropy_with_logits_v2(labels = true_cls_ids_one_hot, \n",
    "                                                        logits = predict_cls_ids)\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============假设部分参数值========================\n",
    "predict_cls_ids = tf.constant(np.array([[[1,0],[0,1],[0,1]]]), dtype=tf.float32)\n",
    "true_cls_ids = tf.constant(np.array([[[0,-1],[1,1],[1,1]]]), dtype=tf.uint8)\n",
    "indices = tf.constant(np.array([[[0,-1],[1,1],[2,1]]]), dtype=tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前2个维度的索引参数一：\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 2]]\n",
      "batch_num*rpn_train_anchors个打平的anchors索引参数二：\n",
      "[0 1 2]\n",
      "所有anchors对应的真实值标签参数三：\n",
      "[0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# 函数测试：1\n",
    "## 真实值去除padding\n",
    "train_indices = tf.where(tf.not_equal(indices[...,-1], 0)) # 返回2维tensor\n",
    "train_anchor_indices = tf.gather_nd(indices[...,0], train_indices) # 3维tensor确定1个维度，然后gather_nd选定索引2维tensor，最终返回（batch_num*rpn_train_anchors）的1维tensor\n",
    "true_cls_ids = tf.gather_nd(true_cls_ids[...,0], train_indices) # 同样也是返回长度为（batch_num*rpn_train_anchors）的1维cls\n",
    "print(\"前2个维度的索引参数一：\\n{}\".format(train_indices.eval(session=sess)))\n",
    "print(\"batch_num*rpn_train_anchors个打平的anchors索引参数二：\\n{}\".format(train_anchor_indices.eval(session=sess)))\n",
    "print(\"所有anchors对应的真实值标签参数三：\\n{}\".format(true_cls_ids.eval(session=sess)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1]\n",
      "类别真实值“独热”编码：\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 函数测试：2\n",
    "## 真实值one-hot编码\n",
    "## 需要tf.ones_like与tf.zeros_like两个参数，保证满足和不满足判断条件时，对应维度元素的取值是“0”还是“1”.不然tf.where()直接返回满足条件的索引\n",
    "true_cls_ids = tf.where(true_cls_ids >= 1,\n",
    "                        tf.ones_like(true_cls_ids, dtype=tf.uint8),\n",
    "                        tf.zeros_like(true_cls_ids, dtype=tf.uint8))\n",
    "true_cls_ids_one_hot = tf.one_hot(true_cls_ids, depth=2)\n",
    "print(true_cls_ids.eval(session=sess))\n",
    "print(\"类别真实值“独热”编码：\\n{}\".format(true_cls_ids_one_hot.eval(session=sess)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_indices：\n",
      "[0 0 0]\n",
      "train_anchor_indices_2d：\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 2]]\n",
      "predict_cls_ids：\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 函数测试：3\n",
    "# anchors的2维indices索引,与predict的anchors中用于训练的anchors提取\n",
    "batch_indices = train_indices[:, 0]\n",
    "train_anchor_indices_2d = tf.stack([batch_indices, tf.cast(train_anchor_indices, dtype=tf.int64)], axis=1)\n",
    "predict_cls_ids = tf.gather_nd(predict_cls_ids, train_anchor_indices_2d)\n",
    "print(\"batch_indices：\\n{}\".format(batch_indices.eval(session=sess)))\n",
    "print(\"train_anchor_indices_2d：\\n{}\".format(train_anchor_indices_2d.eval(session=sess)))\n",
    "print(\"predict_cls_ids：\\n{}\".format(predict_cls_ids.eval(session=sess)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "案例tensors的交叉熵loss情况：\n",
      "[0.31326166 0.31326166 0.31326166]\n"
     ]
    }
   ],
   "source": [
    "# 函数测试：4\n",
    "losses = tf.nn.softmax_cross_entropy_with_logits_v2(labels = true_cls_ids_one_hot, \n",
    "                                                    logits = predict_cls_ids)\n",
    "print(\"案例tensors的交叉熵loss情况：\\n{}\".format(losses.eval(session=sess)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先定义smooth_l1_loss的计算过程\n",
    "def smooth_l1_loss(y_true, y_predict):\n",
    "    \"\"\"\n",
    "    smooth L1损失函数；   0.5*x^2 if |x| <1 else |x|-0.5; x是 diff\n",
    "    :param y_true:[N,4]\n",
    "    :param y_predict:[N,4]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 误差绝对值\n",
    "    abs_diff =  tf.abs(y_true - y_predict, name='A')\n",
    "    # 根据abs_diff与数值1的关系，计算各个anchor的smooth_l1_loss，并赋值在指定索引\n",
    "    loss_all = tf.where(tf.less(abs_diff, 1), 0.5 * tf.pow(abs_diff, 2), tf.abs(abs_diff) - 0.5)\n",
    "    # 一个batch共N个anchors的综合smooth_l1_loss\n",
    "    loss = tf.reduce_mean(loss_all, axis=1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 然后从输入处理loss的最终输出\n",
    "def rpn_regress_loss(predict_deltas, deltas, indices):\n",
    "    \"\"\"\n",
    "    :param predict_deltas: 预测的回归目标，(batch_num, anchors_num, 4)\n",
    "    :param deltas: 真实的回归目标，(batch_num, rpn_train_anchors, 4+1), 最后一位为tag, tag=0 为padding\n",
    "    :param indices: 正负样本索引，(batch_num, rpn_train_anchors, (idx,tag))，\n",
    "             idx:指定anchor索引位置，最后一位为tag, tag=0 为padding; 1为正样本，-1为负样本\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 这里只针对正样本做回归\n",
    "    positive_indices = tf.where(tf.equal(indices[...,-1], 1))\n",
    "    true_positive_indices = tf.gather_nd(indices[...,0], positive_indices)\n",
    "    deltas = tf.gather_nd(deltas[...,:-1], positive_indices)\n",
    "    # 找到所有正样本的2维索引indices\n",
    "    batch_indices = positive_indices[:, 0]\n",
    "    positive_indices_2d = tf.stack([batch_indices, tf.cast(true_positive_indices,dtype=tf.uint8)], axis=1)\n",
    "    # 从predict_deltas中筛选出用于计算loss的deltas\n",
    "    predict_deltas = tf.gather_nd(predict_deltas, positive_indices_2d)\n",
    "    # smooth_l1_loss损失\n",
    "    import keras.backend as K\n",
    "    loss = K.switch(tf.size(deltas) > 0,\n",
    "                    smooth_l1_loss(deltas, predict_deltas),\n",
    "                    tf.constant(0.0))\n",
    "    loss = K.mean(loss)\n",
    "    \n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============假设部分参数值========================\n",
    "predict_deltas = tf.constant(np.array([[[78,22,253,304],[269,19,360,296]]]), dtype=tf.float32)\n",
    "deltas = tf.constant(np.array([[[50,30,200,280,1],[280,10,370,320,1]]]), dtype=tf.float32)\n",
    "indices = tf.constant(np.array([[[0,1],[1,1]]]), dtype=tf.int64) # 两个正样本anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "案例tensors的smooth_l1_loss情况：\n",
      "20.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 函数测试：1\n",
    "## 这里只针对正样本做回归\n",
    "positive_indices = tf.where(tf.equal(indices[...,-1], 1))\n",
    "true_positive_indices = tf.gather_nd(indices[...,0], positive_indices)\n",
    "deltas = tf.gather_nd(deltas[...,:-1], positive_indices)\n",
    "# 找到所有正样本的2维索引indices\n",
    "batch_indices = positive_indices[:, 0]\n",
    "positive_indices_2d = tf.stack([batch_indices, tf.cast(true_positive_indices,dtype=tf.int64)], axis=1)\n",
    "# 从predict_deltas中筛选出用于计算loss的deltas\n",
    "predict_deltas = tf.gather_nd(predict_deltas, positive_indices_2d)\n",
    "# smooth_l1_loss损失\n",
    "import keras.backend as K\n",
    "loss = K.switch(tf.size(deltas) > 0,\n",
    "                smooth_l1_loss(deltas, predict_deltas),\n",
    "                tf.constant(0.0))\n",
    "loss = K.mean(loss)\n",
    "print(\"案例tensors的smooth_l1_loss情况：\\n{}\".format(loss.eval(session=sess)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
