{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Royce\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分类loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cls_Loss(pred_cls_ids, true_cls_ids, indices):\n",
    "    \"\"\"\n",
    "    分类的交叉熵损失\n",
    "    pred_cls_ids:（batch_num，anchors_num，class_one-hot）\n",
    "    true_cls_ids:（batch_num，rpn_train_anchors，（class_name，tag）） 0:1:-1\n",
    "    indices:（batch_num，rpn_train_anchors，（ids，tag）） 0:1:-1\n",
    "    \"\"\"\n",
    "    # \n",
    "    train_indices = tf.where(tf.not_equal(indices[...,-1], 0)) # 正、负样本计算分类的loss\n",
    "    true_cls_ids = tf.gather_nd(true_cls_ids[...,0], train_indices) # 2维tensr的2维gather_nd，返回一维\n",
    "    train_anchor_indices = tf.gather_nd(indices[...,0], train_indices) # 2维tensor的2维gather_nd，返回一维\n",
    "    #==========================================\n",
    "    # 稀疏编码转one-hot编码，只用区分前景、背景\n",
    "    true_cls_ids = tf.where(true_cls_ids > 0,\n",
    "                            tf.ones_like(true_cls_ids, dtype=tf.int32),\n",
    "                            tf.zeros_like(true_cls_ids, dtype=tf.int32))\n",
    "    true_cls_ids_one_hot = tf.one_hot(true_cls_ids, depth=tf.shape(pred_cls_ids)[-1])\n",
    "    #==========================================\n",
    "    #\n",
    "    batch_indice = train_indices[:, 0]\n",
    "    indices_2d = tf.stack([batch_indice, train_anchor_indices], axis=1) # 这里是把两个1维的合并堆叠为2维，所以用tf.stack()\n",
    "    pred_cls_ids = tf.gather_nd(pred_cls_ids, indices_2d)\n",
    "    loss = tf.nn.softmax_cross_entropy(labels=true_cls_ids_one_hot, logits=pred_cls_ids)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regress_Loss(pred_deltas, deltas, indices):\n",
    "    \"\"\"\n",
    "    回归的smooth_l1损失\n",
    "    pred_deltas:（batch_num，anchors_num，4）\n",
    "    deltas:     （batch_num，rpn_train_anchors，（4，tag））\n",
    "    indices:    （batch_num，rpn_train_anchors，（ids，tag））\n",
    "    \"\"\"\n",
    "    pos_indices_2d = tf.where(tf.equal(indices[...,-1], 1)) # 正样本计算回归的loss\n",
    "    deltas = tf.gather_nd(deltas[...,:-1], pos_indices)\n",
    "    pos_indices_1d = tf.gather_nd(indices[...,0], pos_indices)\n",
    "    #\n",
    "    batch_indices = pos_indices[:, 0]\n",
    "    indices_2d = tf.stack([batch_indices, tf.cast(pos_indices_1d, dtype=tf.int32)], axis=1) # 同样2个1维的，堆叠为2维索引，所以用tf.stack()\n",
    "    pred_deltas = tf.gather_nd(pred_deltas, indices_2d)\n",
    "    #\n",
    "    import keras.backend as K\n",
    "    loss = K.switch(tf.size(deltas) > 0,\n",
    "                    Smooth_l1_Loss(deltas, predict_deltas),\n",
    "                    tf.constant(0.0))\n",
    "    loss = K.mean(loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Smooth_l1_Loss(y_true, y_pred): # 0.5*x^2 if |x| <1 else |x|-0.5; x是 diff\n",
    "    \"\"\"\n",
    "    smooth_l1_loss的计算过程\n",
    "    y_true:（N，4）\n",
    "    y_pred:（N，4）\n",
    "    \"\"\"\n",
    "    abs_diff = tf.abs(y_true - y_pred) \n",
    "    loss_all = tf.where(tf.less(abs_diff, 1) 0.5*tf.pow(abs_diff, 2) tf.abs(abs_diff)-0.5) # tf.where()当有3个参数值时，返回同维度的赋值结果\n",
    "    loss = tf.reduce_mean(loss_all, axis=1)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28.  8. 53. 24.]\n",
      " [11.  9. 10. 24.]]\n",
      "[[ 392.    32.  1404.5  288. ]\n",
      " [  60.5   40.5   50.   288. ]]\n",
      "[529.125 109.75 ]\n"
     ]
    }
   ],
   "source": [
    "predict_deltas = tf.constant(np.array([[78,22,253,304],[269,19,360,296]]), dtype=tf.float32)\n",
    "deltas = tf.constant(np.array([[50,30,200,280],[280,10,370,320]]), dtype=tf.float32)\n",
    "abs_diff = tf.abs(deltas - predict_deltas)\n",
    "print(abs_diff.eval(session=sess))\n",
    "loss_all = 0.5*tf.pow(abs_diff, 2)\n",
    "print(loss_all.eval(session=sess))\n",
    "loss = tf.reduce_mean(loss_all, axis=1)\n",
    "print(loss.eval(session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
